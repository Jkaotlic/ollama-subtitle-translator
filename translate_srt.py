#!/usr/bin/env python3
"""
üé¨ –ü–µ—Ä–µ–≤–æ–¥—á–∏–∫ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ (.srt) —á–µ—Ä–µ–∑ Ollama
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥–µ–ª—å Translating Gemma (Google) ‚Äî —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞.

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ —è–∑—ã–∫–æ–≤: —Ä—É—Å—Å–∫–∏–π, –∞–Ω–≥–ª–∏–π—Å–∫–∏–π, –∫–∏—Ç–∞–π—Å–∫–∏–π, —è–ø–æ–Ω—Å–∫–∏–π, –∫–æ—Ä–µ–π—Å–∫–∏–π,
–Ω–µ–º–µ—Ü–∫–∏–π, —Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π, –∏—Å–ø–∞–Ω—Å–∫–∏–π, –∏—Ç–∞–ª—å—è–Ω—Å–∫–∏–π, –ø–æ—Ä—Ç—É–≥–∞–ª—å—Å–∫–∏–π –∏ –¥—Ä.

–£—Å—Ç–∞–Ω–æ–≤–∫–∞:
  1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Ollama: https://ollama.com/download
  2. ollama pull translategemma:4b
  3. pip install requests

–ü—Ä–∏–º–µ—Ä—ã:
  python translate_srt.py movie.srt                    # EN‚ÜíRU (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
  python translate_srt.py movie.srt -l Japanese        # EN‚ÜíJP
  python translate_srt.py movie.srt -l German -o de.srt
"""

import argparse
import re
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import List, Tuple, Optional, Dict
import time
import uuid
import logging

logger = logging.getLogger("translate_srt")

try:
    import requests
except ImportError:
    print("‚ùå –ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω requests: pip install requests")
    sys.exit(1)


# –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —è–∑—ã–∫–∏ –∏ –∏—Ö –∫–æ–¥—ã –¥–ª—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
LANGUAGES = {
    "russian": "ru", "ru": "ru", "—Ä—É—Å—Å–∫–∏–π": "ru",
    "english": "en", "en": "en", "–∞–Ω–≥–ª–∏–π—Å–∫–∏–π": "en",
    "chinese": "zh", "zh": "zh", "–∫–∏—Ç–∞–π—Å–∫–∏–π": "zh",
    "japanese": "ja", "ja": "ja", "—è–ø–æ–Ω—Å–∫–∏–π": "ja",
    "korean": "ko", "ko": "ko", "–∫–æ—Ä–µ–π—Å–∫–∏–π": "ko",
    "german": "de", "de": "de", "–Ω–µ–º–µ—Ü–∫–∏–π": "de",
    "french": "fr", "fr": "fr", "—Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π": "fr",
    "spanish": "es", "es": "es", "–∏—Å–ø–∞–Ω—Å–∫–∏–π": "es",
    "italian": "it", "it": "it", "–∏—Ç–∞–ª—å—è–Ω—Å–∫–∏–π": "it",
    "portuguese": "pt", "pt": "pt", "–ø–æ—Ä—Ç—É–≥–∞–ª—å—Å–∫–∏–π": "pt",
    "turkish": "tr", "tr": "tr", "—Ç—É—Ä–µ—Ü–∫–∏–π": "tr",
    "arabic": "ar", "ar": "ar", "–∞—Ä–∞–±—Å–∫–∏–π": "ar",
    "thai": "th", "th": "th", "—Ç–∞–π—Å–∫–∏–π": "th",
    "vietnamese": "vi", "vi": "vi", "–≤—å–µ—Ç–Ω–∞–º—Å–∫–∏–π": "vi",
    "polish": "pl", "pl": "pl", "–ø–æ–ª—å—Å–∫–∏–π": "pl",
    "dutch": "nl", "nl": "nl", "–≥–æ–ª–ª–∞–Ω–¥—Å–∫–∏–π": "nl",
    "ukrainian": "uk", "uk": "uk", "—É–∫—Ä–∞–∏–Ω—Å–∫–∏–π": "uk",
}

# –†–µ–≥—É–ª—è—Ä–∫–∞ –¥–ª—è —Ç–∞–π–º–∫–æ–¥–æ–≤ SRT
TIME_RE = re.compile(r"^\d{2}:\d{2}:\d{2},\d{3}\s*-->\s*\d{2}:\d{2}:\d{2},\d{3}.*$")
# –†–µ–≥—É–ª—è—Ä–∫–∞ –¥–ª—è HTML-—Ç–µ–≥–æ–≤ (—Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Ö)
TAG_RE = re.compile(r"(<[^>]+>|{\\\w+\d*})")


def post_with_retry(url: str, json: dict, timeout: int = 120, attempts: int = 3, backoff: float = 1.0) -> Optional[requests.Response]:
    """POST with simple exponential backoff retry. Returns Response or None."""
    last_exc = None
    for attempt in range(1, attempts + 1):
        t0 = time.time()
        try:
            resp = requests.post(url, json=json, timeout=timeout)
            elapsed = time.time() - t0
            logger.info("POST %s attempt=%d status=%d elapsed=%.2fs", url, attempt, resp.status_code, elapsed)
            return resp
        except requests.RequestException as e:
            elapsed = time.time() - t0
            last_exc = e
            sleep = backoff * (2 ** (attempt - 1))
            logger.warning("POST %s attempt=%d failed (%.2fs): %s ‚Äî retrying in %.1fs", url, attempt, elapsed, e, sleep)
            time.sleep(sleep)
    logger.error("post_with_retry exhausted %d attempts to %s: %s", attempts, url, last_exc)
    return None


@dataclass
class SrtBlock:
    """–û–¥–∏–Ω –±–ª–æ–∫ —Å—É–±—Ç–∏—Ç—Ä–æ–≤."""
    index: int
    timecode: str
    lines: Tuple[str, ...]

    def text(self) -> str:
        return "\n".join(self.lines)


def read_srt_file(path: Path) -> Tuple[str, str]:
    """–ß–∏—Ç–∞–µ—Ç —Ñ–∞–π–ª —Å –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫–∏ (chardet ‚Üí fallback —Ü–µ–ø–æ—á–∫–∞)."""
    raw = path.read_bytes()
    if raw.startswith(b"\xef\xbb\xbf"):
        return raw.decode("utf-8-sig"), "utf-8-sig"
    try:
        return raw.decode("utf-8"), "utf-8"
    except UnicodeDecodeError:
        pass
    # –ü—Ä–æ–±—É–µ–º chardet –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
    try:
        import chardet
        detected = chardet.detect(raw)
        enc = detected.get("encoding")
        if enc:
            logger.info("chardet detected encoding=%s confidence=%.2f", enc, detected.get("confidence", 0))
            return raw.decode(enc), enc
    except ImportError:
        pass
    except (UnicodeDecodeError, LookupError):
        pass
    # Fallback –Ω–∞ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ —Å—É–±—Ç–∏—Ç—Ä–æ–≤
    for enc in ("cp1251", "latin-1", "iso-8859-2", "shift_jis"):
        try:
            return raw.decode(enc), enc
        except (UnicodeDecodeError, LookupError):
            continue
    # –ö—Ä–∞–π–Ω–∏–π fallback
    return raw.decode("utf-8", errors="replace"), "utf-8"


def parse_srt(text: str) -> List[SrtBlock]:
    """–ü–∞—Ä—Å–∏—Ç SRT —Ç–µ–∫—Å—Ç –≤ —Å–ø–∏—Å–æ–∫ –±–ª–æ–∫–æ–≤."""
    text = text.replace("\r\n", "\n").replace("\r", "\n")
    lines = text.split("\n")
    
    blocks: List[SrtBlock] = []
    i = 0
    n = len(lines)
    
    while i < n:
        while i < n and lines[i].strip() == "":
            i += 1
        if i >= n:
            break

        idx_line = lines[i].strip()
        if not idx_line.isdigit():
            i += 1
            continue
        index = int(idx_line)
        i += 1
        
        if i >= n:
            break

        timecode = lines[i].strip()
        if not TIME_RE.match(timecode):
            i += 1
            continue
        i += 1

        text_lines: List[str] = []
        while i < n and lines[i].strip() != "":
            text_lines.append(lines[i])
            i += 1

        blocks.append(SrtBlock(index=index, timecode=timecode, lines=tuple(text_lines)))
        i += 1

    return blocks


def write_srt(blocks: List[SrtBlock], path: Path, encoding: str) -> None:
    """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –±–ª–æ–∫–∏ –≤ SRT —Ñ–∞–π–ª."""
    out_lines: List[str] = []
    for b in blocks:
        out_lines.append(str(b.index))
        out_lines.append(b.timecode)
        out_lines.extend(b.lines)
        out_lines.append("")
    path.write_text("\n".join(out_lines).rstrip("\n") + "\n", encoding=encoding)


def protect_tags(text: str) -> Tuple[str, Dict[str, str]]:
    """–ó–∞—â–∏—â–∞–µ—Ç —Ç–µ–≥–∏ –æ—Ç –ø–µ—Ä–µ–≤–æ–¥–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∑–∞—â–∏—â—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏ map placeholder->tag."""
    tags: Dict[str, str] = {}

    def replacer(match):
        key = f"__TAG_{uuid.uuid4().hex}__"
        tags[key] = match.group(0)
        return key

    protected = TAG_RE.sub(replacer, text)
    return protected, tags


def restore_tags(text: str, tags: Dict[str, str]) -> str:
    """–í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ç–µ–≥–∏ –∏–∑ —Å–ª–æ–≤–∞—Ä—è –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä->–æ—Ä–∏–≥–∏–Ω–∞–ª."""
    for k, v in tags.items():
        text = text.replace(k, v)
    return text


def validate_translation(original: str, translated: str) -> bool:
    """Check if translated text looks reasonable compared to original.

    Returns True if the translation passes basic quality checks.
    """
    if not translated or not translated.strip():
        return False
    # Translation is identical to source (model didn't translate)
    if translated.strip() == original.strip():
        return False
    # Translation is absurdly longer than original (likely hallucination)
    if len(translated) > len(original) * 5 and len(original) > 10:
        return False
    # Translation is just punctuation or whitespace
    stripped = re.sub(r'[\s\W]+', '', translated)
    if not stripped:
        return False
    return True


class Translator:
    """–ü–µ—Ä–µ–≤–æ–¥—á–∏–∫ —á–µ—Ä–µ–∑ Ollama + Translating Gemma"""

    def __init__(self, model: str = "translategemma:4b", target_lang: str = "Russian",
                 ollama_url: str = "http://127.0.0.1:11434", context: str = "",
                 temperature: float = 0.0, source_lang: str = "",
                 two_pass: bool = False, review_model: str = ""):
        self.model = model
        self.target_lang = target_lang
        self.source_lang = source_lang  # –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ = –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        self.base_url = ollama_url
        self.context = context
        self.temperature = float(temperature)

        self.two_pass = two_pass
        self.review_model = review_model or model  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ç–∞ –∂–µ –º–æ–¥–µ–ª—å
        self._cache: Dict[str, str] = {}
        self._cache_hits = 0

        # Quick connectivity check (model availability already verified by web UI)
        try:
            resp = requests.get(f"{self.base_url}/api/tags", timeout=3)
            if resp.status_code != 200:
                raise Exception("Ollama –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç")
            # When called from CLI, verify model exists
            if sys.stdin and sys.stdin.isatty():
                available = [m["name"] for m in resp.json().get("models", [])]
                if not any(model in m for m in available):
                    print(f"‚ö†Ô∏è  –ú–æ–¥–µ–ª—å {model} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –î–æ—Å—Ç—É–ø–Ω—ã–µ: {available}")
                    print(f"   –ó–∞–ø—É—Å—Ç–∏—Ç–µ: ollama pull {model}")
                    sys.exit(1)
                if self.two_pass and self.review_model != model:
                    if not any(self.review_model in m for m in available):
                        print(f"‚ö†Ô∏è  Review-–º–æ–¥–µ–ª—å {self.review_model} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
                        sys.exit(1)
        except requests.exceptions.ConnectionError:
            raise RuntimeError("Ollama –Ω–µ –∑–∞–ø—É—â–µ–Ω! –ó–∞–ø—É—Å—Ç–∏—Ç–µ: ollama serve")

        logger.info("Translator ready: model=%s lang=%s two_pass=%s", model, target_lang, two_pass)

    def translate(self, text: str, prev_text: str = "", next_text: str = "") -> str:
        """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç —Ç–µ–∫—Å—Ç —Å —É—á—ë—Ç–æ–º —Å–æ—Å–µ–¥–Ω–∏—Ö —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –¥–ª—è —Å–≤—è–∑–Ω–æ—Å—Ç–∏."""
        if not text.strip():
            return text

        # Cache lookup ‚Äî –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Ñ—Ä–∞–∑—ã –ø–µ—Ä–µ–≤–æ–¥—è—Ç—Å—è –æ–¥–∏–Ω–∞–∫–æ–≤–æ
        cache_key = text.strip()
        if cache_key in self._cache:
            self._cache_hits += 1
            logger.debug("translate: cache hit #%d for '%s'", self._cache_hits, cache_key[:40])
            return self._cache[cache_key]

        logger.debug("translate: input length=%d chars", len(text))
        protected_text, tags = protect_tags(text)

        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç —Å —É—á—ë—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        parts: List[str] = []
        if self.context and self.context.strip():
            parts.append(f"Context: {self.context.strip()}")

        # Sliding window: —Å–æ—Å–µ–¥–Ω–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã –¥–∞—é—Ç –º–æ–¥–µ–ª–∏ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞
        if prev_text or next_text:
            parts.append("Surrounding subtitles for reference (do NOT translate these):")
            if prev_text:
                parts.append(f"[BEFORE]: {prev_text}")
            if next_text:
                parts.append(f"[AFTER]: {next_text}")
            parts.append("")

        from_part = f" from {self.source_lang}" if self.source_lang else ""
        parts.append(
            f"Translate the following subtitle{from_part} into {self.target_lang}. "
            "Keep it concise for subtitles. Provide only the translation, nothing else."
        )
        parts.append(f"\n{protected_text}")
        prompt = "\n".join(parts)

        payload = {"model": self.model, "prompt": prompt, "stream": False}
        # include temperature if applicable
        if self.temperature is not None:
            payload["temperature"] = float(self.temperature)

        resp = post_with_retry(
            f"{self.base_url}/api/generate",
            json=payload,
            timeout=120,
            attempts=3,
            backoff=1.0,
        )

        if resp is None:
            logger.error("Ollama request failed after retries: model=%s url=%s", self.model, f"{self.base_url}/api/generate")
            return text

        if resp.status_code != 200:
            body = resp.text if hasattr(resp, "text") else ""
            logger.warning("Ollama non-200: status=%d model=%s body=%.200s", resp.status_code, self.model, body)
            return text

        try:
            data = resp.json()
            translated = data.get("response", "").strip()
            logger.debug("translate: model=%s input_len=%d output_len=%d", self.model, len(text), len(translated))
        except Exception:
            try:
                body = resp.text
            except Exception:
                body = ""
            logger.exception("Failed to parse Ollama JSON: model=%s body=%.500s", self.model, body)
            translated = body.strip()

        # Validate quality; retry once if suspicious
        if not validate_translation(text, translated):
            logger.warning("translate: validation failed (original=%d chars, translated=%d chars), retrying once",
                           len(text), len(translated))
            retry_resp = post_with_retry(
                f"{self.base_url}/api/generate", json=payload, timeout=120, attempts=1, backoff=0,
            )
            if retry_resp and retry_resp.status_code == 200:
                try:
                    translated = retry_resp.json().get("response", "").strip()
                except Exception:
                    pass
            # If still bad, return original to avoid garbage in output
            if not validate_translation(text, translated):
                logger.warning("translate: retry also failed validation, returning original text")
                return text

        result = restore_tags(translated, tags)
        self._cache[cache_key] = result
        return result

    def review(self, original: str, translated: str,
               prev_original: str = "", prev_translated: str = "",
               next_original: str = "") -> str:
        """–í—Ç–æ—Ä–æ–π –ø—Ä–æ—Ö–æ–¥: –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∏ –ø—Ä–∞–≤–∏—Ç –ø–µ—Ä–µ–≤–æ–¥ —Å —É—á—ë—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ –∏–ª–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å
        —Ä–µ—à–∏–ª–∞, —á—Ç–æ –ø—Ä–∞–≤–æ–∫ –Ω–µ –Ω—É–∂–Ω–æ.
        """
        if not translated.strip() or not original.strip():
            return translated

        parts: List[str] = []
        if self.context and self.context.strip():
            parts.append(f"Context: {self.context.strip()}")

        # –û–∫—Ä—É–∂–∞—é—â–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞
        if prev_original or next_original:
            parts.append("Surrounding subtitles for reference:")
            if prev_original:
                line = f"[BEFORE]: {prev_original}"
                if prev_translated:
                    line += f" ‚Üí {prev_translated}"
                parts.append(line)
            if next_original:
                parts.append(f"[AFTER]: {next_original}")
            parts.append("")

        from_part = f" from {self.source_lang}" if self.source_lang else ""
        parts.append(
            f"You are reviewing a subtitle translation{from_part} into {self.target_lang}.\n"
            "Check the translation for:\n"
            "- Accuracy: does it convey the original meaning?\n"
            "- Natural flow: does it sound natural in the target language?\n"
            "- Consistency with surrounding subtitles\n"
            "- Conciseness: subtitles must be short (max ~42 chars per line)\n\n"
            f"Original: {original}\n"
            f"Translation: {translated}\n\n"
            "If the translation is good, output it exactly as-is.\n"
            "If it needs fixes, output ONLY the corrected translation, nothing else."
        )
        prompt = "\n".join(parts)

        payload = {"model": self.review_model, "prompt": prompt, "stream": False}
        if self.temperature is not None:
            payload["temperature"] = float(self.temperature)

        resp = post_with_retry(
            f"{self.base_url}/api/generate",
            json=payload,
            timeout=120,
            attempts=2,
            backoff=1.0,
        )

        if resp is None or resp.status_code != 200:
            logger.warning("review: request failed, keeping original translation")
            return translated

        try:
            reviewed = resp.json().get("response", "").strip()
        except Exception:
            return translated

        # –í–∞–ª–∏–¥–∞—Ü–∏—è: reviewed –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–∞–∑—É–º–Ω—ã–º
        if not reviewed or not reviewed.strip():
            return translated
        # –ï—Å–ª–∏ review –≤–µ—Ä–Ω—É–ª —á—Ç–æ-—Ç–æ –≤ 5 —Ä–∞–∑ –¥–ª–∏–Ω–Ω–µ–µ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞ ‚Äî –º—É—Å–æ—Ä
        if len(reviewed) > len(original) * 5 and len(original) > 10:
            logger.warning("review: result too long (%d chars vs %d original), keeping first pass",
                           len(reviewed), len(original))
            return translated

        if reviewed != translated:
            logger.info("review: corrected '%s' ‚Üí '%s'", translated[:50], reviewed[:50])

        return reviewed

    def translate_batch(self, texts: List[str], max_chars: int = 2000) -> List[str]:
        """Translate a list of texts as a single request (or multiple chunked requests).

        Uses sliding window context for per-segment fallback to maintain dialogue coherence.
        Returns list of translated strings in the same order.
        """
        if not texts:
            return []

        # Helper to chunk by character length, returning (start_index, chunk_texts)
        def make_chunks(texts_list, max_chars_local):
            chunks: List[Tuple[int, List[str]]] = []
            cur: List[str] = []
            cur_start = 0
            cur_len = 0
            for i, t in enumerate(texts_list):
                if cur and cur_len + len(t) > max_chars_local:
                    chunks.append((cur_start, cur))
                    cur = []
                    cur_start = i
                    cur_len = 0
                cur.append(t)
                cur_len += len(t)
            if cur:
                chunks.append((cur_start, cur))
            return chunks

        chunks = make_chunks(texts, max_chars)
        results: List[str] = []

        for chunk_idx, (chunk_start, chunk) in enumerate(chunks):
            logger.info("translate_batch: chunk %d/%d segments=%d", chunk_idx + 1, len(chunks), len(chunk))
            # Protect tags per segment
            protected_list = []
            tags_list: List[Dict[str, str]] = []
            for seg in chunk:
                p, tags = protect_tags(seg)
                protected_list.append(p)
                tags_list.append(tags)

            # Build prompt with delimiter-based output format
            segments_payload = "\n|||SEP|||\n".join(protected_list)

            context_line = ""
            if self.context and self.context.strip():
                context_line = f"Context: {self.context.strip()}\n\n"

            from_part = f" from {self.source_lang}" if self.source_lang else ""
            prompt = (
                f"{context_line}"
                f"Translate each segment below{from_part} into {self.target_lang}.\n"
                "Keep translations concise ‚Äî suitable for subtitles (max ~42 characters per line).\n"
                "Preserve any placeholders exactly (e.g. __TAG_xxx__).\n"
                "Separate translated segments with |||SEP||| on its own line.\n"
                "Output ONLY the translations, nothing else.\n\n"
                f"{segments_payload}"
            )

            payload = {"model": self.model, "prompt": prompt, "stream": False}
            if self.temperature is not None:
                payload["temperature"] = float(self.temperature)

            resp = post_with_retry(
                f"{self.base_url}/api/generate",
                json=payload,
                timeout=180,
                attempts=3,
                backoff=1.0,
            )

            if resp is None:
                logger.error("Ollama batch failed: model=%s chunk=%d/%d", self.model, chunk_idx + 1, len(chunks))
                results.extend(chunk)
                continue

            if resp.status_code != 200:
                body = resp.text if hasattr(resp, "text") else ""
                logger.warning("Ollama batch non-200: status=%d model=%s chunk=%d/%d body=%.200s",
                               resp.status_code, self.model, chunk_idx + 1, len(chunks), body)
                results.extend(chunk)
                continue

            # Parse delimiter-based response
            translated_list: List[str] = []
            try:
                data = resp.json()
                model_response = data.get("response", "")
                logger.debug("translate_batch: raw model response (first 500 chars): %.500s", model_response)

                # Split by delimiter
                parts = [p.strip() for p in model_response.split("|||SEP|||")]
                # Remove empty leading/trailing parts
                parts = [p for p in parts if p]

                if len(parts) == len(chunk):
                    translated_list = parts
                else:
                    translated_list = []
            except Exception:
                translated_list = []

            # Validate each translated segment in the batch
            if translated_list and len(translated_list) == len(chunk):
                bad_count = sum(1 for orig, tr in zip(chunk, translated_list) if not validate_translation(orig, tr))
                if bad_count > len(chunk) * 0.5:
                    logger.warning("translate_batch: chunk %d/%d has %d/%d bad translations, falling back",
                                   chunk_idx + 1, len(chunks), bad_count, len(chunk))
                    translated_list = []  # force fallback
                elif bad_count > 0:
                    logger.info("translate_batch: chunk %d/%d has %d/%d suspicious translations",
                                chunk_idx + 1, len(chunks), bad_count, len(chunk))

            if translated_list and len(translated_list) == len(chunk):
                logger.info("translate_batch: chunk %d/%d parsed %d segments OK", chunk_idx + 1, len(chunks), len(translated_list))
            else:
                # Delimiter parsing failed or wrong count ‚Äî fallback to one-by-one with sliding window
                logger.warning("translate_batch: chunk %d/%d delimiter parse failed (got %d, expected %d), falling back to per-segment translation",
                               chunk_idx + 1, len(chunks), len(translated_list) if translated_list else 0, len(chunk))
                translated_list = []
                for seg_idx, seg in enumerate(chunk):
                    # Sliding window: pass neighboring subtitles for coherence
                    global_idx = chunk_start + seg_idx
                    prev_text = texts[global_idx - 1] if global_idx > 0 else ""
                    next_text = texts[global_idx + 1] if global_idx < len(texts) - 1 else ""
                    translated = self.translate(seg, prev_text=prev_text, next_text=next_text)
                    translated_list.append(translated)
                    logger.debug("translate_batch fallback: seg %d/%d done", seg_idx + 1, len(chunk))

            # Restore tags
            for translated, tags in zip(translated_list, tags_list):
                restored = restore_tags(translated, tags)
                results.append(restored)

        # Second pass: review each translation for quality
        if self.two_pass and results:
            logger.info("translate_batch: starting review pass (%d segments)", len(results))
            reviewed: List[str] = []
            for i, (orig, trans) in enumerate(zip(texts, results)):
                prev_orig = texts[i - 1] if i > 0 else ""
                prev_trans = results[i - 1] if i > 0 else ""
                next_orig = texts[i + 1] if i < len(texts) - 1 else ""
                corrected = self.review(
                    orig, trans,
                    prev_original=prev_orig,
                    prev_translated=prev_trans,
                    next_original=next_orig,
                )
                reviewed.append(corrected)
            logger.info("translate_batch: review pass done")
            return reviewed

        return results


def translate_srt(input_path: Path, output_path: Path, target_lang: str = "Russian",
                  model: str = "translategemma:4b", batch_size: int = 10,
                  context: str = "", source_lang: str = "",
                  two_pass: bool = False, review_model: str = "") -> None:
    """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç SRT —Ñ–∞–π–ª."""
    print(f"üìñ –ß–∏—Ç–∞—é: {input_path}")
    text, encoding = read_srt_file(input_path)
    blocks = parse_srt(text)
    print(f"   –°—É–±—Ç–∏—Ç—Ä–æ–≤: {len(blocks)}")

    translator = Translator(model, target_lang, context=context, source_lang=source_lang,
                            two_pass=two_pass, review_model=review_model)
    
    print(f"üîÑ –ü–µ—Ä–µ–≤–æ–¥...")
    translated_blocks: List[SrtBlock] = []
    total = len(blocks)
    
    for i, block in enumerate(blocks):
        prev_text = blocks[i - 1].text() if i > 0 else ""
        next_text = blocks[i + 1].text() if i < total - 1 else ""
        translated_text = translator.translate(block.text(), prev_text=prev_text, next_text=next_text)
        translated_lines = tuple(translated_text.split("\n"))
        translated_blocks.append(SrtBlock(
            index=block.index,
            timecode=block.timecode,
            lines=translated_lines
        ))
        
        # –ü—Ä–æ–≥—Ä–µ—Å—Å
        if (i + 1) % batch_size == 0 or i == total - 1:
            pct = (i + 1) / total * 100
            bar_len = 30
            filled = int(bar_len * (i + 1) / total)
            bar = "‚ñà" * filled + "‚ñë" * (bar_len - filled)
            print(f"   [{bar}] {i+1}/{total} ({pct:.1f}%)", end="\r")
    
    print()
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è—é: {output_path}")
    write_srt(translated_blocks, output_path, "utf-8")
    print("‚úÖ –ì–æ—Ç–æ–≤–æ!")


def main():
    parser = argparse.ArgumentParser(
        description="üé¨ –ü–µ—Ä–µ–≤–æ–¥—á–∏–∫ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ (Ollama + Translating Gemma)"
    )
    parser.add_argument("input", type=Path, help="–í—Ö–æ–¥–Ω–æ–π SRT —Ñ–∞–π–ª")
    parser.add_argument("--out", "-o", type=Path, default=None, help="–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª")
    parser.add_argument("--lang", "-l", type=str, default="Russian", help="–¶–µ–ª–µ–≤–æ–π —è–∑—ã–∫")
    parser.add_argument("--model", "-m", type=str, default="translategemma:4b", help="–ú–æ–¥–µ–ª—å Ollama")
    parser.add_argument("--batch", "-b", type=int, default=10, help="–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞")
    parser.add_argument("--context", "-c", type=str, default="", help="–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä: '–°–µ—Ä–∏–∞–ª –æ –±–æ–ª—å–Ω–∏—Ü–µ —Å –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–µ–π')")
    parser.add_argument("--source-lang", "-s", type=str, default="", help="–ò—Å—Ö–æ–¥–Ω—ã–π —è–∑—ã–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä: English). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ")
    parser.add_argument("--two-pass", action="store_true", help="–î–≤—É—Ö–ø—Ä–æ—Ö–æ–¥–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥: translate ‚Üí review")
    parser.add_argument("--review-model", type=str, default="", help="–ú–æ–¥–µ–ª—å –¥–ª—è review-–ø—Ä–æ—Ö–æ–¥–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî —Ç–∞ –∂–µ)")

    args = parser.parse_args()
    
    if not args.input.exists():
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.input}")
        sys.exit(1)
    
    lang_key = args.lang.lower()
    lang_code = LANGUAGES.get(lang_key, lang_key[:2].lower())
    
    output_path = args.out
    if output_path is None:
        stem = args.input.stem
        output_path = args.input.with_name(f"{stem}.{lang_code}.srt")
    
    translate_srt(args.input, output_path, args.lang, args.model, args.batch, args.context,
                  args.source_lang, args.two_pass, args.review_model)


if __name__ == "__main__":
    main()
