services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_NUM_PARALLEL=2
      - OLLAMA_MAX_LOADED_MODELS=1
    restart: unless-stopped
    # Для Windows x64 с Docker Desktop CPU-режим
    # GPU поддержка на Windows требует WSL2 + NVIDIA Container Toolkit

  model-init:
    image: curlimages/curl:latest
    container_name: model-init
    depends_on:
      - ollama
    volumes:
      - ./init-model.sh:/init-model.sh:ro
    entrypoint: ["/bin/sh", "/init-model.sh"]
    restart: "no"

  translator:
    build: .
    container_name: subtitle-translator
    ports:
      - "8847:8847"
    environment:
      - OLLAMA_URL=http://ollama:11434
      - VIDEO_DIR=/videos
    volumes:
      - ${VIDEO_HOST_DIR:-/mnt/media}:/videos:ro
    depends_on:
      - ollama
      - model-init
    restart: unless-stopped

volumes:
  ollama_data:
